{"cells":[{"cell_type":"markdown","metadata":{},"source":["# A notebook on the Eron Dataset from Kaggle\n","This notebook was found through the following [link](https://www.kaggle.com/code/conniedeng/nlp-eron-dataset?fbclid=IwAR3k6TfBRz842eBrj3l3pOY9a3qSiO3r1JqhI2UeLCx9slJU4RrQvrt-D0w)."]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"ename":"ImportError","evalue":"cannot import name 'HttpReader' from 'torchtext._download_hooks' (c:\\Users\\Jonathan Dragestad M\\OneDrive\\Dokumenter\\02456_project_group_72\\.venv\\lib\\site-packages\\torchtext\\_download_hooks.py)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn [26], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mif\u001b[39;00m is_module_available(\u001b[39m\"\u001b[39m\u001b[39mtorchdata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     12\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39miter\u001b[39;00m \u001b[39mimport\u001b[39;00m FileOpener, IterableWrapper\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_download_hooks\u001b[39;00m \u001b[39mimport\u001b[39;00m HttpReader\n\u001b[0;32m     15\u001b[0m URL \u001b[39m=\u001b[39m {\n\u001b[0;32m     16\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mhttps://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.train.txt\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mhttps://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.test.txt\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mhttps://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.valid.txt\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m }\n\u001b[0;32m     21\u001b[0m MD5 \u001b[39m=\u001b[39m {\n\u001b[0;32m     22\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mf26c4b92c5fdc7b3f8c7cdcb991d8420\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39maa0affc06ff7c36e977d7cd49e3839bf\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m8b80168b89c18661a38ef683c0dc3721\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m }\n","\u001b[1;31mImportError\u001b[0m: cannot import name 'HttpReader' from 'torchtext._download_hooks' (c:\\Users\\Jonathan Dragestad M\\OneDrive\\Dokumenter\\02456_project_group_72\\.venv\\lib\\site-packages\\torchtext\\_download_hooks.py)"]}],"source":["import os\n","from functools import partial\n","from typing import Tuple, Union\n","\n","from torchtext._internal.module_utils import is_module_available\n","from torchtext.data.datasets_utils import (\n","    _wrap_split_argument,\n","    _create_dataset_directory,\n",")\n","\n","if is_module_available(\"torchdata\"):\n","    from torchdata.datapipes.iter import FileOpener, IterableWrapper\n","    from torchtext._download_hooks import HttpReader\n","\n","URL = {\n","    \"train\": \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.train.txt\",\n","    \"test\": \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.test.txt\",\n","    \"valid\": \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.valid.txt\",\n","}\n","\n","MD5 = {\n","    \"train\": \"f26c4b92c5fdc7b3f8c7cdcb991d8420\",\n","    \"valid\": \"aa0affc06ff7c36e977d7cd49e3839bf\",\n","    \"test\": \"8b80168b89c18661a38ef683c0dc3721\",\n","}\n","\n","NUM_LINES = {\n","    \"train\": 42068,\n","    \"valid\": 3370,\n","    \"test\": 3761,\n","}\n","\n","DATASET_NAME = \"PennTreebank\"\n","\n","\n","def _filepath_fn(root, split, _=None):\n","    return os.path.join(root, os.path.basename(URL[split]))\n","\n","\n","def _modify_res(t):\n","    return t.strip()\n","\n","\n","[docs]@_create_dataset_directory(dataset_name=DATASET_NAME)\n","@_wrap_split_argument((\"train\", \"valid\", \"test\"))\n","def PennTreebank(root, split: Union[Tuple[str], str]):\n","    \"\"\"PennTreebank Dataset\n","\n","    .. warning::\n","\n","        using datapipes is still currently subject to a few caveats. if you wish\n","        to use this dataset with shuffling, multi-processing, or distributed\n","        learning, please see :ref:`this note <datapipes_warnings>` for further\n","        instructions.\n","\n","    For additional details refer to https://catalog.ldc.upenn.edu/docs/LDC95T7/cl93.html\n","\n","    Number of lines per split:\n","        - train: 42068\n","        - valid: 3370\n","        - test: 3761\n","\n","    Args:\n","        root: Directory where the datasets are saved. Default: os.path.expanduser('~/.torchtext/cache')\n","        split: split or splits to be returned. Can be a string or tuple of strings. Default: (`train`, `valid`, `test`)\n","\n","    :returns: DataPipe that yields text from the Treebank corpus\n","    :rtype: str\n","    \"\"\"\n","    if not is_module_available(\"torchdata\"):\n","        raise ModuleNotFoundError(\n","            \"Package `torchdata` not found. Please install following instructions at https://github.com/pytorch/data\"\n","        )\n","\n","    url_dp = IterableWrapper([URL[split]])\n","    cache_dp = url_dp.on_disk_cache(\n","        filepath_fn=partial(_filepath_fn, root, split),\n","        hash_dict={_filepath_fn(root, split): MD5[split]},\n","        hash_type=\"md5\",\n","    )\n","    cache_dp = HttpReader(cache_dp).end_caching(mode=\"wb\", same_filepath_fn=True)\n","\n","    data_dp = FileOpener(cache_dp, encoding=\"utf-8\")\n","    # remove single leading and trailing space from the dataset\n","    return data_dp.readlines(return_path=False).map(_modify_res).shuffle().set_shuffle(False).sharding_filter()\n","\n","\n","\n","\n","from torchtext.datasets import IMDB\n","\n","train_iter = IMDB(split='train')\n","\n","def tokenize(label, line):\n","    return line.split()\n","\n","tokens = []\n","for label, line in train_iter:\n","    tokens += tokenize(label, line)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"d96a798051220adb8d47ede7819712d4980d7e1ecee887457e300fc8d0177c4e"}}},"nbformat":4,"nbformat_minor":4}
